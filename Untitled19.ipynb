{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMsvHS+V1KYLmz6sn1Ljo1m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabioRovai/closwap/blob/main/Untitled19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHqfHfHL4OxG",
        "outputId": "3bcd7c4e-f360-4f51-93d8-87bca8e57a77"
      },
      "source": [
        "!git clone https://github.com/shadow2496/VITON-HD.git\n",
        "%cd ./VITON-HD/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VITON-HD'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 34 (delta 10), reused 25 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n",
            "/content/VITON-HD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVMyLmdZfLvV",
        "outputId": "8dc86aa9-fff9-419d-ef16-ebd3934d6275"
      },
      "source": [
        "!pip install torch==1.6.0+cu92 torchvision==0.7.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torch-1.6.0%2Bcu92-cp37-cp37m-linux_x86_64.whl (552.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 552.8 MB 4.2 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.7.0%2Bcu92-cp37-cp37m-linux_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 891 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu92) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu92) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0+cu92) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu111\n",
            "    Uninstalling torchvision-0.10.0+cu111:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.6.0+cu92 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0+cu92 torchvision-0.7.0+cu92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIm18dVvdIqT",
        "outputId": "e89c71f0-f385-4a51-efec-e48d2a2b357b"
      },
      "source": [
        "!pip install opencv-python torchgeometry"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Collecting torchgeometry\n",
            "  Downloading torchgeometry-0.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from torchgeometry) (1.6.0+cu92)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->torchgeometry) (0.16.0)\n",
            "Installing collected packages: torchgeometry\n",
            "Successfully installed torchgeometry-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlFO1H1I4WiI",
        "outputId": "752447bf-e3c1-4b2b-eab6-1f3687c91209"
      },
      "source": [
        "import gdown\n",
        "gdown.download('https://drive.google.com/u/0/uc?export=download&confirm=PAd9&id=1s0r8e4tvQMcp8AD0k7JOHetCEuRuY0Zk', 'checkpoints-20211102T134153Z-001.zip', quiet=False)\n",
        "%cd /content/VITON-HD/checkpoints\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?export=download&confirm=PAd9&id=1s0r8e4tvQMcp8AD0k7JOHetCEuRuY0Zk\n",
            "To: /content/VITON-HD/checkpoints-20211102T134153Z-001.zip\n",
            "100%|██████████| 572M/572M [00:11<00:00, 51.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VITON-HD/checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfyqmdPINuwN",
        "outputId": "24f10058-d998-4932-b055-246e11525e74"
      },
      "source": [
        "\n",
        "import zipfile\n",
        "path_to_zip_file='/content/VITON-HD/checkpoints-20211102T134153Z-001.zip'\n",
        "directory_to_extract_to='content/VITON-HD/checkpoints'\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "%cd ..\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VITON-HD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bWkX-Gdzlxq"
      },
      "source": [
        "%mv /content/VITON-HD/checkpoints/content/VITON-HD/checkpoints/checkpoints/*.pth /content/VITON-HD/checkpoints"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfFy0ssI0WOE",
        "outputId": "adaff69d-6f2c-48bb-872f-c1987dd2fb3d"
      },
      "source": [
        "!wget  https://github.com/FabioRovai/test7/blob/main/datasets-20211102T134151Z-001.zip?raw=true -O datasets-20211102T134151Z-001.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-03 12:42:04--  https://github.com/FabioRovai/test7/blob/main/datasets-20211102T134151Z-001.zip?raw=true\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/FabioRovai/test7/raw/main/datasets-20211102T134151Z-001.zip [following]\n",
            "--2021-11-03 12:42:05--  https://github.com/FabioRovai/test7/raw/main/datasets-20211102T134151Z-001.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/FabioRovai/test7/main/datasets-20211102T134151Z-001.zip [following]\n",
            "--2021-11-03 12:42:05--  https://raw.githubusercontent.com/FabioRovai/test7/main/datasets-20211102T134151Z-001.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2691018 (2.6M) [application/zip]\n",
            "Saving to: ‘datasets-20211102T134151Z-001.zip’\n",
            "\n",
            "datasets-20211102T1 100%[===================>]   2.57M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-11-03 12:42:06 (32.3 MB/s) - ‘datasets-20211102T134151Z-001.zip’ saved [2691018/2691018]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsEeVtVBO5Ye",
        "outputId": "9e04f0ff-dc28-4391-cb14-35636520c63c"
      },
      "source": [
        "!unzip /content/VITON-HD/datasets-20211102T134151Z-001.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/VITON-HD/datasets-20211102T134151Z-001.zip\n",
            "  inflating: datasets/test_pairs.txt  \n",
            "  inflating: datasets/test.zip       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL_p-NNDQTtA"
      },
      "source": [
        "!unzip /content/VITON-HD/datasets/test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34gdq5Jg0yCy"
      },
      "source": [
        "%mv /content/VITON-HD/test /content/VITON-HD/datasets"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsDiYqq_WqUc",
        "outputId": "9ed7a32b-c252-4d0d-b596-dc5772c78387"
      },
      "source": [
        "import torch \n",
        "!nvidia-smi"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov  3 12:43:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    36W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPbi1Le7XfnB",
        "outputId": "0c9e7f06-e989-45d3-952d-902f9c260d49"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U481borQa_s",
        "outputId": "be46d0ec-629a-40a9-8063-b2dca9a9f136"
      },
      "source": [
        "#%env CUDA_VISIBLE_DEVICES=[GPU_ID] \n",
        "!python /content/VITON-HD/test.py --name [NAME]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(alias_checkpoint='alias_final.pth', batch_size=1, checkpoint_dir='./checkpoints/', dataset_dir='./datasets/', dataset_list='test_pairs.txt', dataset_mode='test', display_freq=1, gmm_checkpoint='gmm_final.pth', grid_size=5, init_type='xavier', init_variance=0.02, load_height=1024, load_width=768, name='[NAME]', ngf=64, norm_G='spectralaliasinstance', num_upsampling_layers='most', save_dir='./results/', seg_checkpoint='seg_final.pth', semantic_nc=13, shuffle=False, workers=1)\n",
            "Network [SegGenerator] was created. Total number of parameters: 34.5 million. To see the architecture, do print(network).\n",
            "Network [ALIASGenerator] was created. Total number of parameters: 100.5 million. To see the architecture, do print(network).\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3384: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "step: 1\n",
            "step: 2\n",
            "step: 3\n",
            "step: 4\n",
            "step: 5\n",
            "step: 6\n"
          ]
        }
      ]
    }
  ]
}